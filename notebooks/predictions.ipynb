{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas scikit-learn\n",
    "# ! pip install pandas scikit-learn pymongo pylance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job_role_Accountant' 'job_role_CTO' 'job_role_Customer Support Agent'\n",
      " 'job_role_Customer Support Manager' 'job_role_Data Engineer I'\n",
      " 'job_role_Data Engineer II' 'job_role_Financial Analyst'\n",
      " 'job_role_HR Manager' 'job_role_HR Specialist'\n",
      " 'job_role_Marketing Specialist' 'job_role_Network Engineer'\n",
      " 'job_role_Operations Director' 'job_role_Product Manager'\n",
      " 'job_role_Program Manager' 'job_role_Project Manager'\n",
      " 'job_role_SEO Specialist' 'job_role_Sales Representative'\n",
      " 'job_role_Social Media Agent' 'job_role_Software Engineer I'\n",
      " 'job_role_Software Engineer II' 'job_role_Sr Data Engineer'\n",
      " 'job_role_Sr Software Engineer' 'job_role_System Administrator'\n",
      " 'job_role_Systems Analyst' 'job_role_Talent Acquisition'\n",
      " 'office_loc_Atlanta' 'office_loc_Boston' 'office_loc_Dallas'\n",
      " 'office_loc_Hartford' 'office_loc_Houston' 'office_loc_Irvine'\n",
      " 'office_loc_London' 'office_loc_Minneapolis' 'office_loc_New York'\n",
      " 'office_loc_Paris' 'office_loc_Portland' 'office_loc_Providence'\n",
      " 'office_loc_San Diego' 'office_loc_Seattle' 'office_loc_St Louis'\n",
      " 'office_loc_St Paul' 'office_loc_Tokyo']\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 800 stored elements and shape (400, 42)>\n",
      "  Coords\tValues\n",
      "  (0, 17)\t1.0\n",
      "  (0, 35)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 33)\t1.0\n",
      "  (2, 5)\t1.0\n",
      "  (2, 25)\t1.0\n",
      "  (3, 20)\t1.0\n",
      "  (3, 28)\t1.0\n",
      "  (4, 10)\t1.0\n",
      "  (4, 29)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (5, 35)\t1.0\n",
      "  (6, 23)\t1.0\n",
      "  (6, 31)\t1.0\n",
      "  (7, 8)\t1.0\n",
      "  (7, 33)\t1.0\n",
      "  (8, 4)\t1.0\n",
      "  (8, 28)\t1.0\n",
      "  (9, 8)\t1.0\n",
      "  (9, 26)\t1.0\n",
      "  (10, 20)\t1.0\n",
      "  (10, 39)\t1.0\n",
      "  (11, 22)\t1.0\n",
      "  (11, 41)\t1.0\n",
      "  (12, 2)\t1.0\n",
      "  :\t:\n",
      "  (387, 38)\t1.0\n",
      "  (388, 1)\t1.0\n",
      "  (388, 26)\t1.0\n",
      "  (389, 12)\t1.0\n",
      "  (389, 28)\t1.0\n",
      "  (390, 11)\t1.0\n",
      "  (390, 37)\t1.0\n",
      "  (391, 0)\t1.0\n",
      "  (391, 37)\t1.0\n",
      "  (392, 10)\t1.0\n",
      "  (392, 34)\t1.0\n",
      "  (393, 15)\t1.0\n",
      "  (393, 34)\t1.0\n",
      "  (394, 13)\t1.0\n",
      "  (394, 31)\t1.0\n",
      "  (395, 17)\t1.0\n",
      "  (395, 29)\t1.0\n",
      "  (396, 20)\t1.0\n",
      "  (396, 34)\t1.0\n",
      "  (397, 11)\t1.0\n",
      "  (397, 38)\t1.0\n",
      "  (398, 23)\t1.0\n",
      "  (398, 28)\t1.0\n",
      "  (399, 8)\t1.0\n",
      "  (399, 41)\t1.0\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "\n",
    "# Assuming your JSON data is in a file named 'employee_data.json'\n",
    "with open('../mongodb/MOCK_DATA(1).json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Remove dollar sign and convert salary to numeric\n",
    "df['salary'] = df['salary'].str.replace('$', '', regex=False).astype(float)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "X= df[['job_role','office_loc']]\n",
    "y=df['salary']\n",
    "\n",
    "column_transformer = ColumnTransformer([('encoder', OneHotEncoder(), [0, 1])], remainder='passthrough')\n",
    "X_encoded = column_transformer.fit_transform(X)\n",
    "\n",
    "# columns = X.columns\n",
    "encoded_feature_names = column_transformer.named_transformers_['encoder'].get_feature_names_out(X.columns.tolist())\n",
    "print(encoded_feature_names)\n",
    "\n",
    "\n",
    "\n",
    " # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# columns = df.columns\n",
    "model = LinearRegression()\n",
    "   \n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# encoder.fit(data)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(X_test)\n",
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Make the file path to save the pipeline\n",
    "file_path = 'model.pkl'\n",
    "file_path2 = 'columns.pkl'\n",
    "\n",
    "# Send the pipeline to disk\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Send the model columns to disk\n",
    "with open(file_path2, 'wb') as file:\n",
    "    pickle.dump(encoded_feature_names, file)\n",
    "\n",
    "# Save the encoders\n",
    "with open('location_encoder.pkl', 'wb') as location_file:\n",
    "    pickle.dump(label_encoder, location_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
